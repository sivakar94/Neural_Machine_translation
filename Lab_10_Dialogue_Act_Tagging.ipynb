{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab 10 Dialogue Act Tagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "9_ZORURKg-fp"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 10: Dialogue Act Tagging\n",
        "\n",
        "Dialogue act (DA) tagging is an important step in the process of developing dialog systems. DA tagging is a problem usually solved by supervised machine learning approaches that all require large amounts of hand labeled data. A wide range of techniques have been investigated for DA tagging. In this lab, we explore two models for DA classification. We are using the Switchboard Dialog Act Corpus for training.\n",
        "Corpus can be downloaded from http://compprag.christopherpotts.net/swda.html.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ziKyA9R4gyw9"
      },
      "cell_type": "markdown",
      "source": [
        "The downloaded dataset should be kept in a data folder in the same directory as this file. "
      ]
    },
    {
      "metadata": {
        "id": "Invd78QekWFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Sivakar Sivarajah"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jmTpKt_uefe5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0tnK8vgYEc0A",
        "colab_type": "code",
        "outputId": "6e8b45f1-dbce-4531-8029-ef95c07f0800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://compprag.christopherpotts.net/code-data/swda.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"swda.zip\",\"r\") as zip_ref:\n",
        "   zip_ref.extractall(\"/content\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-28 07:23:07--  http://compprag.christopherpotts.net/code-data/swda.zip\n",
            "Resolving compprag.christopherpotts.net (compprag.christopherpotts.net)... 64.90.36.20\n",
            "Connecting to compprag.christopherpotts.net (compprag.christopherpotts.net)|64.90.36.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14040987 (13M) [application/zip]\n",
            "Saving to: ‘swda.zip’\n",
            "\n",
            "swda.zip            100%[===================>]  13.39M  9.01MB/s    in 1.5s    \n",
            "\n",
            "2019-03-28 07:23:09 (9.01 MB/s) - ‘swda.zip’ saved [14040987/14040987]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6E8axaw1hAbM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f = glob.glob(\"swda/sw*/sw*.csv\")\n",
        "frames = []\n",
        "for i in range(0, len(f)):\n",
        "    frames.append(pd.read_csv(f[i]))\n",
        "\n",
        "result = pd.concat(frames, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFB-vHGLEZMb",
        "colab_type": "code",
        "outputId": "8219c6a1-f203-40a3-965f-1aa1dd209bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5362
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>swda_filename</th>\n",
              "      <th>ptb_basename</th>\n",
              "      <th>conversation_no</th>\n",
              "      <th>transcript_index</th>\n",
              "      <th>act_tag</th>\n",
              "      <th>caller</th>\n",
              "      <th>utterance_index</th>\n",
              "      <th>subutterance_index</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>trees</th>\n",
              "      <th>ptb_treenumbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>0</td>\n",
              "      <td>o</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Okay, {F uh. } /</td>\n",
              "      <td>Okay/UH ,/,  [ uh/UH ] ./.</td>\n",
              "      <td>(INTJ (UH Okay) (, ,))|||(INTJ (UH uh) (. .) (...</td>\n",
              "      <td>1|||2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>1</td>\n",
              "      <td>qy</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Do you have annual family reunions  /</td>\n",
              "      <td>Do/VBP  [ you/PRP ] have/VB  [ annual/JJ famil...</td>\n",
              "      <td>(SQ (VBP Do) (NP-SBJ (PRP you)) (VP (VB have) ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>2</td>\n",
              "      <td>%</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{C or, } -/</td>\n",
              "      <td>or/CC ,/,</td>\n",
              "      <td>(S-UNF (CC or) (, ,) (-DFL- N_S))</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>3</td>\n",
              "      <td>ny</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>{F Uh, } yeah,  /</td>\n",
              "      <td>[ Uh/UH ] ,/, yeah/UH ,/,</td>\n",
              "      <td>(INTJ (INTJ (UH Uh)) (, ,) (INTJ (UH yeah)) (,...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>4</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>{F uh, }  our, - /</td>\n",
              "      <td>[ uh/UH ] ,/,  [ our/PRP$ ] ,/,</td>\n",
              "      <td>(S (INTJ (UH uh)) (, ,) (NP-SBJ-UNF (PRP$ our)...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>5</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>the - /</td>\n",
              "      <td>[ the/DT</td>\n",
              "      <td>(S (NP-SBJ-UNF (DT the)) (-DFL- N_S))</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>6</td>\n",
              "      <td>sd^e</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>my mother's side of the family  [ is quite lar...</td>\n",
              "      <td>my/PRP$ mother/NN 's/POS side/NN ] of/IN  [ th...</td>\n",
              "      <td>(S (NP-SBJ (NP (NP (PRP$ my) (NN mother) (POS ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>7</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>{C and, }  {F uh, } &lt;throat_clearing&gt; they, {F...</td>\n",
              "      <td>and/CC ,/,  [ uh/UH ] ,/,  [ they/PRP ] ,/,  [...</td>\n",
              "      <td>(S (CC and) (, ,) (INTJ (UH uh)) (, ,) (NP-SBJ...</td>\n",
              "      <td>11|||12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>8</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>back,  {F uh, } early on they used [ to, +  to...</td>\n",
              "      <td>back/RB ,/,  [ uh/UH ] ,/, early/RB on/IN  [ t...</td>\n",
              "      <td>(S (INTJ (UH um)) (, ,) (-DFL- E_S) (ADVP-TMP ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>9</td>\n",
              "      <td>b</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Uh-huh. /</td>\n",
              "      <td>[ Uh-huh/UH ] ./.</td>\n",
              "      <td>(INTJ (UH Uh-huh) (. .) (-DFL- E_S))</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>10</td>\n",
              "      <td>+</td>\n",
              "      <td>B</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>in the family.  &lt;sigh&gt;  /</td>\n",
              "      <td>in/IN  [ the/DT family/NN ] ./.</td>\n",
              "      <td>(S (INTJ (UH um)) (, ,) (-DFL- E_S) (ADVP-TMP ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>11</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>{C And, } -/</td>\n",
              "      <td>And/CC ,/,</td>\n",
              "      <td>(S-UNF (CC And) (, ,) (-DFL- N_S))</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>12</td>\n",
              "      <td>qy^d</td>\n",
              "      <td>A</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>All local.  /</td>\n",
              "      <td>All/DT local/JJ ./.</td>\n",
              "      <td>(NP (NP (DT All)) (ADJP (JJ local)) (. .) (-DF...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>13</td>\n",
              "      <td>qy</td>\n",
              "      <td>A</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>Were they {D like } all in Dallas? /</td>\n",
              "      <td>[ Were/VBD ] [ they/PRP ] like/UH  [ all/DT ] ...</td>\n",
              "      <td>(SQ (VBD Were) (NP-SBJ (NP (PRP they)) (INTJ (...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>14</td>\n",
              "      <td>nn</td>\n",
              "      <td>B</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>{F Uh, } [ [ [ no, + no ] + not, ] + no, ]  /</td>\n",
              "      <td>[ Uh/UH ] ,/, no/UH ,/, no/UH not/RB ,/,  [ no...</td>\n",
              "      <td>(INTJ (INTJ (UH Uh)) (, ,) (EDITED (RM (-DFL- ...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>15</td>\n",
              "      <td>sd^e</td>\n",
              "      <td>B</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>this was,  {D well, } I am actually from Missi...</td>\n",
              "      <td>[ this/DT ] was/VBD ,/, well/UH ,/,  [ I/PRP ]...</td>\n",
              "      <td>(S (NP-SBJ (DT this)) (VP-UNF (VBD was) (, ,) ...</td>\n",
              "      <td>22|||23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>16</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>{C and,</td>\n",
              "      <td>and/CC ,/,</td>\n",
              "      <td>(S (CC and) (, ,) (INTJ (UH uh)) (, ,) (NP-SBJ...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>17</td>\n",
              "      <td>bk</td>\n",
              "      <td>A</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Oh. /</td>\n",
              "      <td>Oh/UH ./.</td>\n",
              "      <td>(INTJ (UH Oh) (. .) (-DFL- E_S))</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>18</td>\n",
              "      <td>+</td>\n",
              "      <td>B</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>{C so }  that's, - /</td>\n",
              "      <td>so/RB  [ that/DT ] 's/BES ,/,</td>\n",
              "      <td>(S (EDITED (CC and) (, ,)) (RB so) (NP-SBJ (DT...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>19</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>[ it,  + it ] was around there generally. /</td>\n",
              "      <td>[ it/PRP ] ,/,  [ it/PRP ] was/VBD around/IN t...</td>\n",
              "      <td>(S (EDITED (RM (-DFL- \\[)) (NP-SBJ (PRP it)) (...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>20</td>\n",
              "      <td>b</td>\n",
              "      <td>A</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Uh-huh,  /</td>\n",
              "      <td>[ Uh-huh/UH ] ,/,</td>\n",
              "      <td>(INTJ (UH Uh-huh) (, ,) (-DFL- E_S))</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>21</td>\n",
              "      <td>b^r</td>\n",
              "      <td>A</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>uh-huh. /</td>\n",
              "      <td>[ uh-huh/UH ] ./.</td>\n",
              "      <td>(INTJ (UH uh-huh) (. .) (-DFL- E_S))</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>22</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>{F Uh, } that's where the family --</td>\n",
              "      <td>[ Uh/UH ] ,/,  [ that/DT ] 's/BES where/WRB  [...</td>\n",
              "      <td>(S (INTJ (UH Uh)) (, ,) (NP-SBJ (DT that)) (VP...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>23</td>\n",
              "      <td>qy^d</td>\n",
              "      <td>A</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>Just from city to city then  ((   )) . /</td>\n",
              "      <td>Just/RB from/IN  [ city/NN ] to/IN  [ city/NN ...</td>\n",
              "      <td>(FRAG (ADVP (RB Just)) (PP (IN from) (NP (NN c...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>24</td>\n",
              "      <td>+</td>\n",
              "      <td>B</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>-- grew.  /</td>\n",
              "      <td>--/: grew/VBD ./.</td>\n",
              "      <td>(S (INTJ (UH Uh)) (, ,) (NP-SBJ (DT that)) (VP...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>25</td>\n",
              "      <td>ny</td>\n",
              "      <td>B</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>Yeah,  /</td>\n",
              "      <td>Yeah/UH ,/,</td>\n",
              "      <td>(INTJ (UH Yeah) (, ,) (-DFL- E_S))</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>26</td>\n",
              "      <td>sd^e</td>\n",
              "      <td>B</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>{C and } it was not only in Mississippi, in so...</td>\n",
              "      <td>and/CC  [ it/PRP ] was/VBD not/RB only/RB in/I...</td>\n",
              "      <td>(S (CC and) (NP-SBJ (PRP it)) (VP (VBD was) (P...</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>27</td>\n",
              "      <td>b</td>\n",
              "      <td>A</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>Uh-huh,  /</td>\n",
              "      <td>[ Uh-huh/UH ] ,/,</td>\n",
              "      <td>(INTJ (UH Uh-huh) (, ,) (-DFL- E_S))</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>28</td>\n",
              "      <td>b^r</td>\n",
              "      <td>A</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>uh-huh. /</td>\n",
              "      <td>[ uh-huh/UH ] ./.</td>\n",
              "      <td>(INTJ (UH uh-huh) (. .) (-DFL- E_S))</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>sw04utt/sw_0414_3067.utt</td>\n",
              "      <td>3/sw3067</td>\n",
              "      <td>3067</td>\n",
              "      <td>29</td>\n",
              "      <td>+</td>\n",
              "      <td>B</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>as well,  /</td>\n",
              "      <td>as/IN well/RB ,/,</td>\n",
              "      <td>(S (CC and) (NP-SBJ (PRP it)) (VP (VBD was) (P...</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223576</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>251</td>\n",
              "      <td>+</td>\n",
              "      <td>A</td>\n",
              "      <td>152</td>\n",
              "      <td>1</td>\n",
              "      <td>That [ it could be, + it could be ] added to a...</td>\n",
              "      <td>That/IN  [ it/PRP ] could/MD be/VB ,/,  [ it/P...</td>\n",
              "      <td>(S (CC and) (NP-SBJ-2 (PRP I)) (VP (VBD felt) ...</td>\n",
              "      <td>359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223577</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>252</td>\n",
              "      <td>sd</td>\n",
              "      <td>A</td>\n",
              "      <td>152</td>\n",
              "      <td>2</td>\n",
              "      <td>this is the way I feel about this,  /</td>\n",
              "      <td>[ this/DT ] is/VBZ  [ the/DT way/NN ] [ I/PRP ...</td>\n",
              "      <td>(S (NP-SBJ (DT this)) (VP (VBZ is) (NP-PRD (NP...</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223578</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>253</td>\n",
              "      <td>sd</td>\n",
              "      <td>A</td>\n",
              "      <td>152</td>\n",
              "      <td>3</td>\n",
              "      <td>{C and } this is the way, because [ [ I, + it'...</td>\n",
              "      <td>and/CC  [ this/DT ] is/VBZ  [ the/DT way/NN ] ...</td>\n",
              "      <td>(S (CC and) (NP-SBJ (DT this)) (VP (VBZ is) (N...</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223579</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>254</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>152</td>\n",
              "      <td>4</td>\n",
              "      <td>[ [ [ when you, + when you, ] + if you, ] + if...</td>\n",
              "      <td>when/WRB  [ you/PRP ] ,/, when/WRB  [ you/PRP ...</td>\n",
              "      <td>(S (EDITED (RM (-DFL- \\[)) (EDITED (RM (-DFL- ...</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223580</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>255</td>\n",
              "      <td>b</td>\n",
              "      <td>B</td>\n",
              "      <td>153</td>\n",
              "      <td>1</td>\n",
              "      <td>Uh-huh. /</td>\n",
              "      <td>[ Uh-huh/UH ] ./.</td>\n",
              "      <td>(INTJ (UH Uh-huh) (. .) (-DFL- E_S))</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223581</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>256</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>154</td>\n",
              "      <td>1</td>\n",
              "      <td>{C But } if no one does anything when they're ...</td>\n",
              "      <td>But/CC if/IN  [ no/DT one/NN ] does/VBZ  [ any...</td>\n",
              "      <td>(S-2 (CC But) (SBAR-ADV (IN if) (S (NP-SBJ (DT...</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223582</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>257</td>\n",
              "      <td>aa</td>\n",
              "      <td>B</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes.  /</td>\n",
              "      <td>Yes/UH ./.</td>\n",
              "      <td>(INTJ (UH Yes) (. .) (-DFL- E_S))</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223583</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>258</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>155</td>\n",
              "      <td>2</td>\n",
              "      <td>I'm saying this as I'm trying to keep my nine ...</td>\n",
              "      <td>[ I/PRP ] 'm/VBP saying/VBG  [ this/DT ] as/IN...</td>\n",
              "      <td>(S (NP-SBJ (PRP I)) (VP (VBP 'm) (VP (VBG sayi...</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223584</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>259</td>\n",
              "      <td>b</td>\n",
              "      <td>A</td>\n",
              "      <td>156</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;laughter&gt;  Yes,  /</td>\n",
              "      <td>Yes/UH ,/,</td>\n",
              "      <td>(INTJ (UH Yes) (, ,) (-DFL- E_S))</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223585</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>260</td>\n",
              "      <td>ba</td>\n",
              "      <td>A</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>I understand,  /</td>\n",
              "      <td>[ I/PRP ] understand/VBP ,/,</td>\n",
              "      <td>(S (NP-SBJ (PRP I)) (VP (VBP understand)) (, ,...</td>\n",
              "      <td>375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223586</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>261</td>\n",
              "      <td>sd</td>\n",
              "      <td>A</td>\n",
              "      <td>156</td>\n",
              "      <td>3</td>\n",
              "      <td>I wait until I put mine in bed before I make m...</td>\n",
              "      <td>[ I/PRP ] wait/VBP until/IN  [ I/PRP ] put/VBP...</td>\n",
              "      <td>(S (NP-SBJ (PRP I)) (VP (VBP wait) (SBAR-TMP (...</td>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223587</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>262</td>\n",
              "      <td>b</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;laughter&gt;  Yeah,  /</td>\n",
              "      <td>Yeah/UH ,/,</td>\n",
              "      <td>(INTJ (UH Yeah) (, ,) (-DFL- E_S))</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223588</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>263</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>2</td>\n",
              "      <td>{D well, } she's usually in bed by this time,  /</td>\n",
              "      <td>well/UH ,/,  [ she/PRP ] 's/BES usually/RB in/...</td>\n",
              "      <td>(S (INTJ (UH well)) (, ,) (NP-SBJ (PRP she)) (...</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223589</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>264</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>{C but } she's staying up late tonight.  /</td>\n",
              "      <td>but/CC  [ she/PRP ] 's/BES staying/VBG up/RP  ...</td>\n",
              "      <td>(S (CC but) (NP-SBJ (PRP she)) (VP (BES 's) (V...</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223590</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>265</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>4</td>\n",
              "      <td>{C But, } - /</td>\n",
              "      <td>But/CC ,/,</td>\n",
              "      <td>(S-UNF (CC But) (, ,) (-DFL- N_S))</td>\n",
              "      <td>381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223591</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>266</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>5</td>\n",
              "      <td>yeah,  /</td>\n",
              "      <td>yeah/UH ,/,</td>\n",
              "      <td>(INTJ (UH yeah) (, ,) (-DFL- E_S))</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223592</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>267</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>6</td>\n",
              "      <td>I want to have a relationship with her.  /</td>\n",
              "      <td>[ I/PRP ] want/VBP to/TO have/VB  [ a/DT relat...</td>\n",
              "      <td>(S (NP-SBJ-1 (PRP I)) (VP (VBP want) (S (NP-SB...</td>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223593</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>268</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>7</td>\n",
              "      <td>{D You know, } my dad was a very traditional d...</td>\n",
              "      <td>[ You/PRP ] know/VBP ,/,  [ my/PRP$ dad/NN ] w...</td>\n",
              "      <td>(S (PRN (S (NP-SBJ (PRP You)) (VP (VBP know)))...</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223594</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>269</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>8</td>\n",
              "      <td>{C and } when I was a child I didn't really kn...</td>\n",
              "      <td>and/CC when/WRB  [ I/PRP ] was/VBD  [ a/DT chi...</td>\n",
              "      <td>(S (CC and) (SBAR-TMP (WHADVP-1 (WRB when)) (S...</td>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223595</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>270</td>\n",
              "      <td>sd</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>9</td>\n",
              "      <td>{C and } I miss that.   /</td>\n",
              "      <td>and/CC  [ I/PRP ] miss/VBP  [ that/DT ] ./.</td>\n",
              "      <td>(S (CC and) (NP-SBJ (PRP I)) (VP (VBP miss) (N...</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223596</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>271</td>\n",
              "      <td>%</td>\n",
              "      <td>B</td>\n",
              "      <td>157</td>\n",
              "      <td>10</td>\n",
              "      <td>{C And } I want, -/</td>\n",
              "      <td>And/CC  [ I/PRP ] want/VBP ,/,</td>\n",
              "      <td>(S (CC And) (NP-SBJ (PRP I)) (VP-UNF (VBP want...</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223597</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>272</td>\n",
              "      <td>aa</td>\n",
              "      <td>A</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>That's the thing,  /</td>\n",
              "      <td>[ That/DT ] 's/BES  [ the/DT thing/NN ] ,/,</td>\n",
              "      <td>(S (NP-SBJ (DT That)) (VP (BES 's) (NP-PRD (DT...</td>\n",
              "      <td>389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223598</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>273</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>[ if woman's role, + like we said, if women's ...</td>\n",
              "      <td>if/IN  [ woman/NN 's/POS role/NN ] ,/, like/IN...</td>\n",
              "      <td>(S (EDITED (RM (-DFL- \\[)) (SBAR (IN if) (S-UN...</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223599</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>274</td>\n",
              "      <td>aa</td>\n",
              "      <td>B</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>Yeah,  /</td>\n",
              "      <td>Yeah/UH ,/,</td>\n",
              "      <td>(INTJ (UH Yeah) (, ,) (-DFL- E_S))</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223600</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>275</td>\n",
              "      <td>sv</td>\n",
              "      <td>B</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>{C but } men have to be convinced of that. /</td>\n",
              "      <td>but/CC  [ men/NNS ] have/VBP to/TO be/VB convi...</td>\n",
              "      <td>(S (CC but) (NP-SBJ-1 (NNS men)) (VP (VBP have...</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223601</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>276</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>{C And } a lot of it's for the better.  /</td>\n",
              "      <td>And/CC  [ a/DT lot/NN ] of/IN  [ it/PRP ] 's/B...</td>\n",
              "      <td>(S (CC And) (NP-SBJ (NP (DT a) (NN lot)) (PP (...</td>\n",
              "      <td>395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223602</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>277</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>160</td>\n",
              "      <td>2</td>\n",
              "      <td>[ Some of the, + some of the ] women's roles, ...</td>\n",
              "      <td>[ Some/DT ] of/IN  [ the/DT ] ,/,  [ some/DT ]...</td>\n",
              "      <td>(S-2 (EDITED (RM (-DFL- \\[)) (NP-SBJ (NP (DT S...</td>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223603</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>278</td>\n",
              "      <td>sv</td>\n",
              "      <td>A</td>\n",
              "      <td>160</td>\n",
              "      <td>3</td>\n",
              "      <td>{C but } I think [ if we can, + if we can ] ex...</td>\n",
              "      <td>but/CC  [ I/PRP ] think/VBP if/IN  [ we/PRP ] ...</td>\n",
              "      <td>(S (CC but) (NP-SBJ (PRP I)) (VP (VBP think) (...</td>\n",
              "      <td>397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223604</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>279</td>\n",
              "      <td>aa</td>\n",
              "      <td>B</td>\n",
              "      <td>161</td>\n",
              "      <td>1</td>\n",
              "      <td>No. /</td>\n",
              "      <td>[ No/UH ] ./.</td>\n",
              "      <td>(INTJ (UH No) (. .) (-DFL- E_S))</td>\n",
              "      <td>399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223605</th>\n",
              "      <td>sw01utt/sw_0115_2370.utt</td>\n",
              "      <td>2/sw2370</td>\n",
              "      <td>2370</td>\n",
              "      <td>280</td>\n",
              "      <td>sd</td>\n",
              "      <td>A</td>\n",
              "      <td>162</td>\n",
              "      <td>1</td>\n",
              "      <td>-- I know mine almost never did ... /</td>\n",
              "      <td>--/:  [ I/PRP ] know/VBP  [ mine/PRP$ ] almost...</td>\n",
              "      <td>(S (NP-SBJ (PRP I)) (VP (VBP know) (SBAR (-NON...</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223606 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   swda_filename ptb_basename  conversation_no  \\\n",
              "0       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "1       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "2       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "3       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "4       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "5       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "6       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "7       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "8       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "9       sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "10      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "11      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "12      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "13      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "14      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "15      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "16      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "17      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "18      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "19      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "20      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "21      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "22      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "23      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "24      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "25      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "26      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "27      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "28      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "29      sw04utt/sw_0414_3067.utt     3/sw3067             3067   \n",
              "...                          ...          ...              ...   \n",
              "223576  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223577  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223578  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223579  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223580  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223581  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223582  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223583  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223584  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223585  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223586  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223587  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223588  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223589  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223590  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223591  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223592  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223593  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223594  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223595  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223596  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223597  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223598  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223599  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223600  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223601  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223602  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223603  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223604  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "223605  sw01utt/sw_0115_2370.utt     2/sw2370             2370   \n",
              "\n",
              "        transcript_index act_tag caller  utterance_index  subutterance_index  \\\n",
              "0                      0       o      B                1                   1   \n",
              "1                      1      qy      A                2                   1   \n",
              "2                      2       %      A                2                   2   \n",
              "3                      3      ny      B                3                   1   \n",
              "4                      4       %      B                3                   2   \n",
              "5                      5       %      B                3                   3   \n",
              "6                      6    sd^e      B                3                   4   \n",
              "7                      7      sd      B                3                   5   \n",
              "8                      8      sd      B                3                   6   \n",
              "9                      9       b      A                4                   1   \n",
              "10                    10       +      B                5                   1   \n",
              "11                    11       %      B                5                   2   \n",
              "12                    12    qy^d      A                6                   1   \n",
              "13                    13      qy      A                6                   2   \n",
              "14                    14      nn      B                7                   1   \n",
              "15                    15    sd^e      B                7                   2   \n",
              "16                    16       %      B                7                   3   \n",
              "17                    17      bk      A                8                   1   \n",
              "18                    18       +      B                9                   1   \n",
              "19                    19      sd      B                9                   2   \n",
              "20                    20       b      A               10                   1   \n",
              "21                    21     b^r      A               10                   2   \n",
              "22                    22      sd      B               11                   1   \n",
              "23                    23    qy^d      A               12                   1   \n",
              "24                    24       +      B               13                   1   \n",
              "25                    25      ny      B               13                   2   \n",
              "26                    26    sd^e      B               13                   3   \n",
              "27                    27       b      A               14                   1   \n",
              "28                    28     b^r      A               14                   2   \n",
              "29                    29       +      B               15                   1   \n",
              "...                  ...     ...    ...              ...                 ...   \n",
              "223576               251       +      A              152                   1   \n",
              "223577               252      sd      A              152                   2   \n",
              "223578               253      sd      A              152                   3   \n",
              "223579               254      sv      A              152                   4   \n",
              "223580               255       b      B              153                   1   \n",
              "223581               256      sv      A              154                   1   \n",
              "223582               257      aa      B              155                   1   \n",
              "223583               258      sd      B              155                   2   \n",
              "223584               259       b      A              156                   1   \n",
              "223585               260      ba      A              156                   2   \n",
              "223586               261      sd      A              156                   3   \n",
              "223587               262       b      B              157                   1   \n",
              "223588               263      sd      B              157                   2   \n",
              "223589               264      sd      B              157                   3   \n",
              "223590               265       %      B              157                   4   \n",
              "223591               266       %      B              157                   5   \n",
              "223592               267      sd      B              157                   6   \n",
              "223593               268      sd      B              157                   7   \n",
              "223594               269      sd      B              157                   8   \n",
              "223595               270      sd      B              157                   9   \n",
              "223596               271       %      B              157                  10   \n",
              "223597               272      aa      A              158                   1   \n",
              "223598               273      sv      A              158                   2   \n",
              "223599               274      aa      B              159                   1   \n",
              "223600               275      sv      B              159                   2   \n",
              "223601               276      sv      A              160                   1   \n",
              "223602               277      sv      A              160                   2   \n",
              "223603               278      sv      A              160                   3   \n",
              "223604               279      aa      B              161                   1   \n",
              "223605               280      sd      A              162                   1   \n",
              "\n",
              "                                                     text  \\\n",
              "0                                        Okay, {F uh. } /   \n",
              "1                   Do you have annual family reunions  /   \n",
              "2                                             {C or, } -/   \n",
              "3                                       {F Uh, } yeah,  /   \n",
              "4                                      {F uh, }  our, - /   \n",
              "5                                                 the - /   \n",
              "6       my mother's side of the family  [ is quite lar...   \n",
              "7       {C and, }  {F uh, } <throat_clearing> they, {F...   \n",
              "8       back,  {F uh, } early on they used [ to, +  to...   \n",
              "9                                               Uh-huh. /   \n",
              "10                              in the family.  <sigh>  /   \n",
              "11                                           {C And, } -/   \n",
              "12                                          All local.  /   \n",
              "13                   Were they {D like } all in Dallas? /   \n",
              "14          {F Uh, } [ [ [ no, + no ] + not, ] + no, ]  /   \n",
              "15      this was,  {D well, } I am actually from Missi...   \n",
              "16                                                {C and,   \n",
              "17                                                  Oh. /   \n",
              "18                                   {C so }  that's, - /   \n",
              "19            [ it,  + it ] was around there generally. /   \n",
              "20                                             Uh-huh,  /   \n",
              "21                                              uh-huh. /   \n",
              "22                    {F Uh, } that's where the family --   \n",
              "23               Just from city to city then  ((   )) . /   \n",
              "24                                            -- grew.  /   \n",
              "25                                               Yeah,  /   \n",
              "26      {C and } it was not only in Mississippi, in so...   \n",
              "27                                             Uh-huh,  /   \n",
              "28                                              uh-huh. /   \n",
              "29                                            as well,  /   \n",
              "...                                                   ...   \n",
              "223576  That [ it could be, + it could be ] added to a...   \n",
              "223577              this is the way I feel about this,  /   \n",
              "223578  {C and } this is the way, because [ [ I, + it'...   \n",
              "223579  [ [ [ when you, + when you, ] + if you, ] + if...   \n",
              "223580                                          Uh-huh. /   \n",
              "223581  {C But } if no one does anything when they're ...   \n",
              "223582                                            Yes.  /   \n",
              "223583  I'm saying this as I'm trying to keep my nine ...   \n",
              "223584                                <laughter>  Yes,  /   \n",
              "223585                                   I understand,  /   \n",
              "223586  I wait until I put mine in bed before I make m...   \n",
              "223587                               <laughter>  Yeah,  /   \n",
              "223588   {D well, } she's usually in bed by this time,  /   \n",
              "223589         {C but } she's staying up late tonight.  /   \n",
              "223590                                      {C But, } - /   \n",
              "223591                                           yeah,  /   \n",
              "223592         I want to have a relationship with her.  /   \n",
              "223593  {D You know, } my dad was a very traditional d...   \n",
              "223594  {C and } when I was a child I didn't really kn...   \n",
              "223595                          {C and } I miss that.   /   \n",
              "223596                                {C And } I want, -/   \n",
              "223597                               That's the thing,  /   \n",
              "223598  [ if woman's role, + like we said, if women's ...   \n",
              "223599                                           Yeah,  /   \n",
              "223600       {C but } men have to be convinced of that. /   \n",
              "223601          {C And } a lot of it's for the better.  /   \n",
              "223602  [ Some of the, + some of the ] women's roles, ...   \n",
              "223603  {C but } I think [ if we can, + if we can ] ex...   \n",
              "223604                                              No. /   \n",
              "223605              -- I know mine almost never did ... /   \n",
              "\n",
              "                                                      pos  \\\n",
              "0                              Okay/UH ,/,  [ uh/UH ] ./.   \n",
              "1       Do/VBP  [ you/PRP ] have/VB  [ annual/JJ famil...   \n",
              "2                                               or/CC ,/,   \n",
              "3                               [ Uh/UH ] ,/, yeah/UH ,/,   \n",
              "4                         [ uh/UH ] ,/,  [ our/PRP$ ] ,/,   \n",
              "5                                                [ the/DT   \n",
              "6       my/PRP$ mother/NN 's/POS side/NN ] of/IN  [ th...   \n",
              "7       and/CC ,/,  [ uh/UH ] ,/,  [ they/PRP ] ,/,  [...   \n",
              "8       back/RB ,/,  [ uh/UH ] ,/, early/RB on/IN  [ t...   \n",
              "9                                       [ Uh-huh/UH ] ./.   \n",
              "10                        in/IN  [ the/DT family/NN ] ./.   \n",
              "11                                             And/CC ,/,   \n",
              "12                                    All/DT local/JJ ./.   \n",
              "13      [ Were/VBD ] [ they/PRP ] like/UH  [ all/DT ] ...   \n",
              "14      [ Uh/UH ] ,/, no/UH ,/, no/UH not/RB ,/,  [ no...   \n",
              "15      [ this/DT ] was/VBD ,/, well/UH ,/,  [ I/PRP ]...   \n",
              "16                                             and/CC ,/,   \n",
              "17                                              Oh/UH ./.   \n",
              "18                          so/RB  [ that/DT ] 's/BES ,/,   \n",
              "19      [ it/PRP ] ,/,  [ it/PRP ] was/VBD around/IN t...   \n",
              "20                                      [ Uh-huh/UH ] ,/,   \n",
              "21                                      [ uh-huh/UH ] ./.   \n",
              "22      [ Uh/UH ] ,/,  [ that/DT ] 's/BES where/WRB  [...   \n",
              "23      Just/RB from/IN  [ city/NN ] to/IN  [ city/NN ...   \n",
              "24                                      --/: grew/VBD ./.   \n",
              "25                                            Yeah/UH ,/,   \n",
              "26      and/CC  [ it/PRP ] was/VBD not/RB only/RB in/I...   \n",
              "27                                      [ Uh-huh/UH ] ,/,   \n",
              "28                                      [ uh-huh/UH ] ./.   \n",
              "29                                      as/IN well/RB ,/,   \n",
              "...                                                   ...   \n",
              "223576  That/IN  [ it/PRP ] could/MD be/VB ,/,  [ it/P...   \n",
              "223577  [ this/DT ] is/VBZ  [ the/DT way/NN ] [ I/PRP ...   \n",
              "223578  and/CC  [ this/DT ] is/VBZ  [ the/DT way/NN ] ...   \n",
              "223579  when/WRB  [ you/PRP ] ,/, when/WRB  [ you/PRP ...   \n",
              "223580                                  [ Uh-huh/UH ] ./.   \n",
              "223581  But/CC if/IN  [ no/DT one/NN ] does/VBZ  [ any...   \n",
              "223582                                         Yes/UH ./.   \n",
              "223583  [ I/PRP ] 'm/VBP saying/VBG  [ this/DT ] as/IN...   \n",
              "223584                                         Yes/UH ,/,   \n",
              "223585                       [ I/PRP ] understand/VBP ,/,   \n",
              "223586  [ I/PRP ] wait/VBP until/IN  [ I/PRP ] put/VBP...   \n",
              "223587                                        Yeah/UH ,/,   \n",
              "223588  well/UH ,/,  [ she/PRP ] 's/BES usually/RB in/...   \n",
              "223589  but/CC  [ she/PRP ] 's/BES staying/VBG up/RP  ...   \n",
              "223590                                         But/CC ,/,   \n",
              "223591                                        yeah/UH ,/,   \n",
              "223592  [ I/PRP ] want/VBP to/TO have/VB  [ a/DT relat...   \n",
              "223593  [ You/PRP ] know/VBP ,/,  [ my/PRP$ dad/NN ] w...   \n",
              "223594  and/CC when/WRB  [ I/PRP ] was/VBD  [ a/DT chi...   \n",
              "223595        and/CC  [ I/PRP ] miss/VBP  [ that/DT ] ./.   \n",
              "223596                     And/CC  [ I/PRP ] want/VBP ,/,   \n",
              "223597        [ That/DT ] 's/BES  [ the/DT thing/NN ] ,/,   \n",
              "223598  if/IN  [ woman/NN 's/POS role/NN ] ,/, like/IN...   \n",
              "223599                                        Yeah/UH ,/,   \n",
              "223600  but/CC  [ men/NNS ] have/VBP to/TO be/VB convi...   \n",
              "223601  And/CC  [ a/DT lot/NN ] of/IN  [ it/PRP ] 's/B...   \n",
              "223602  [ Some/DT ] of/IN  [ the/DT ] ,/,  [ some/DT ]...   \n",
              "223603  but/CC  [ I/PRP ] think/VBP if/IN  [ we/PRP ] ...   \n",
              "223604                                      [ No/UH ] ./.   \n",
              "223605  --/:  [ I/PRP ] know/VBP  [ mine/PRP$ ] almost...   \n",
              "\n",
              "                                                    trees ptb_treenumbers  \n",
              "0       (INTJ (UH Okay) (, ,))|||(INTJ (UH uh) (. .) (...           1|||2  \n",
              "1       (SQ (VBP Do) (NP-SBJ (PRP you)) (VP (VB have) ...               4  \n",
              "2                       (S-UNF (CC or) (, ,) (-DFL- N_S))               5  \n",
              "3       (INTJ (INTJ (UH Uh)) (, ,) (INTJ (UH yeah)) (,...               7  \n",
              "4       (S (INTJ (UH uh)) (, ,) (NP-SBJ-UNF (PRP$ our)...               8  \n",
              "5                   (S (NP-SBJ-UNF (DT the)) (-DFL- N_S))               9  \n",
              "6       (S (NP-SBJ (NP (NP (PRP$ my) (NN mother) (POS ...              10  \n",
              "7       (S (CC and) (, ,) (INTJ (UH uh)) (, ,) (NP-SBJ...         11|||12  \n",
              "8       (S (INTJ (UH um)) (, ,) (-DFL- E_S) (ADVP-TMP ...              12  \n",
              "9                    (INTJ (UH Uh-huh) (. .) (-DFL- E_S))              14  \n",
              "10      (S (INTJ (UH um)) (, ,) (-DFL- E_S) (ADVP-TMP ...              12  \n",
              "11                     (S-UNF (CC And) (, ,) (-DFL- N_S))              16  \n",
              "12      (NP (NP (DT All)) (ADJP (JJ local)) (. .) (-DF...              18  \n",
              "13      (SQ (VBD Were) (NP-SBJ (NP (PRP they)) (INTJ (...              19  \n",
              "14      (INTJ (INTJ (UH Uh)) (, ,) (EDITED (RM (-DFL- ...              21  \n",
              "15      (S (NP-SBJ (DT this)) (VP-UNF (VBD was) (, ,) ...         22|||23  \n",
              "16      (S (CC and) (, ,) (INTJ (UH uh)) (, ,) (NP-SBJ...              11  \n",
              "17                       (INTJ (UH Oh) (. .) (-DFL- E_S))              26  \n",
              "18      (S (EDITED (CC and) (, ,)) (RB so) (NP-SBJ (DT...              24  \n",
              "19      (S (EDITED (RM (-DFL- \\[)) (NP-SBJ (PRP it)) (...              28  \n",
              "20                   (INTJ (UH Uh-huh) (, ,) (-DFL- E_S))              30  \n",
              "21                   (INTJ (UH uh-huh) (. .) (-DFL- E_S))              31  \n",
              "22      (S (INTJ (UH Uh)) (, ,) (NP-SBJ (DT that)) (VP...              33  \n",
              "23      (FRAG (ADVP (RB Just)) (PP (IN from) (NP (NN c...              35  \n",
              "24      (S (INTJ (UH Uh)) (, ,) (NP-SBJ (DT that)) (VP...              33  \n",
              "25                     (INTJ (UH Yeah) (, ,) (-DFL- E_S))              37  \n",
              "26      (S (CC and) (NP-SBJ (PRP it)) (VP (VBD was) (P...              38  \n",
              "27                   (INTJ (UH Uh-huh) (, ,) (-DFL- E_S))              30  \n",
              "28                   (INTJ (UH uh-huh) (. .) (-DFL- E_S))              31  \n",
              "29      (S (CC and) (NP-SBJ (PRP it)) (VP (VBD was) (P...              38  \n",
              "...                                                   ...             ...  \n",
              "223576  (S (CC and) (NP-SBJ-2 (PRP I)) (VP (VBD felt) ...             359  \n",
              "223577  (S (NP-SBJ (DT this)) (VP (VBZ is) (NP-PRD (NP...             363  \n",
              "223578  (S (CC and) (NP-SBJ (DT this)) (VP (VBZ is) (N...             364  \n",
              "223579  (S (EDITED (RM (-DFL- \\[)) (EDITED (RM (-DFL- ...             365  \n",
              "223580               (INTJ (UH Uh-huh) (. .) (-DFL- E_S))             340  \n",
              "223581  (S-2 (CC But) (SBAR-ADV (IN if) (S (NP-SBJ (DT...             369  \n",
              "223582                  (INTJ (UH Yes) (. .) (-DFL- E_S))             371  \n",
              "223583  (S (NP-SBJ (PRP I)) (VP (VBP 'm) (VP (VBG sayi...             372  \n",
              "223584                  (INTJ (UH Yes) (, ,) (-DFL- E_S))             374  \n",
              "223585  (S (NP-SBJ (PRP I)) (VP (VBP understand)) (, ,...             375  \n",
              "223586  (S (NP-SBJ (PRP I)) (VP (VBP wait) (SBAR-TMP (...             376  \n",
              "223587                 (INTJ (UH Yeah) (, ,) (-DFL- E_S))             357  \n",
              "223588  (S (INTJ (UH well)) (, ,) (NP-SBJ (PRP she)) (...             379  \n",
              "223589  (S (CC but) (NP-SBJ (PRP she)) (VP (BES 's) (V...             380  \n",
              "223590                 (S-UNF (CC But) (, ,) (-DFL- N_S))             381  \n",
              "223591                 (INTJ (UH yeah) (, ,) (-DFL- E_S))             382  \n",
              "223592  (S (NP-SBJ-1 (PRP I)) (VP (VBP want) (S (NP-SB...             383  \n",
              "223593  (S (PRN (S (NP-SBJ (PRP You)) (VP (VBP know)))...             384  \n",
              "223594  (S (CC and) (SBAR-TMP (WHADVP-1 (WRB when)) (S...             385  \n",
              "223595  (S (CC and) (NP-SBJ (PRP I)) (VP (VBP miss) (N...             386  \n",
              "223596  (S (CC And) (NP-SBJ (PRP I)) (VP-UNF (VBP want...             387  \n",
              "223597  (S (NP-SBJ (DT That)) (VP (BES 's) (NP-PRD (DT...             389  \n",
              "223598  (S (EDITED (RM (-DFL- \\[)) (SBAR (IN if) (S-UN...             390  \n",
              "223599                 (INTJ (UH Yeah) (, ,) (-DFL- E_S))             357  \n",
              "223600  (S (CC but) (NP-SBJ-1 (NNS men)) (VP (VBP have...             393  \n",
              "223601  (S (CC And) (NP-SBJ (NP (DT a) (NN lot)) (PP (...             395  \n",
              "223602  (S-2 (EDITED (RM (-DFL- \\[)) (NP-SBJ (NP (DT S...             396  \n",
              "223603  (S (CC but) (NP-SBJ (PRP I)) (VP (VBP think) (...             397  \n",
              "223604                   (INTJ (UH No) (. .) (-DFL- E_S))             399  \n",
              "223605  (S (NP-SBJ (PRP I)) (VP (VBP know) (SBAR (-NON...             401  \n",
              "\n",
              "[223606 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b7hKGF7EhM4s",
        "outputId": "0eb86102-78b1-48a7-806e-268039bba647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Number of converations in the dataset:\",len(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of converations in the dataset: 223606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0ttyB2lQhc7B"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset has many different features, we are only using act_tag and text for this training.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-jUifIdshhD0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduced_df = result[['act_tag','text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0SB4oj99hiJy",
        "outputId": "101f40a8-b6bc-43fd-e77a-32a4c92472c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "reduced_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act_tag</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>o</td>\n",
              "      <td>Okay, {F uh. } /</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qy</td>\n",
              "      <td>Do you have annual family reunions  /</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>%</td>\n",
              "      <td>{C or, } -/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ny</td>\n",
              "      <td>{F Uh, } yeah,  /</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>%</td>\n",
              "      <td>{F uh, }  our, - /</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  act_tag                                   text\n",
              "0       o                       Okay, {F uh. } /\n",
              "1      qy  Do you have annual family reunions  /\n",
              "2       %                            {C or, } -/\n",
              "3      ny                      {F Uh, } yeah,  /\n",
              "4       %                     {F uh, }  our, - /"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0UNy0vvhhqpD"
      },
      "cell_type": "markdown",
      "source": [
        "Theere are 43 tags in this dataset. Some of the tags are Yes-No-Question('qy'), Statement-non-opinion('sd') and Statement-opinion('sv'). Tags information can be found here http://compprag.christopherpotts.net/swda.html#tags. \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9dR1rKmkh9QG"
      },
      "cell_type": "markdown",
      "source": [
        "You can check the frequency of tags."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x2DzS0iUh-bU",
        "outputId": "3ea32025-e621-450e-da57-d45624dd4a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "reduced_df['act_tag'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sd          70464\n",
              "b           36180\n",
              "sv          25696\n",
              "+           17813\n",
              "%           15547\n",
              "aa          10136\n",
              "ba           4523\n",
              "qy           3785\n",
              "x            3628\n",
              "ny           2826\n",
              "fc           2404\n",
              "b^r          2102\n",
              "sd^e         1939\n",
              "qw           1890\n",
              "sd(^q)       1341\n",
              "bk           1254\n",
              "nn           1230\n",
              "h            1218\n",
              "qy^d         1217\n",
              "bh           1044\n",
              "^q            972\n",
              "bf            934\n",
              "sd^t          929\n",
              "aa^r          916\n",
              "+@            867\n",
              "o             801\n",
              "na            764\n",
              "^2            714\n",
              "b^m           688\n",
              "ad            666\n",
              "            ...  \n",
              "h,sd            1\n",
              "sv(^q)*         1\n",
              "qh(^q)          1\n",
              "qh*             1\n",
              "sd^t*           1\n",
              "fw*             1\n",
              "qh^g            1\n",
              "sd^m*           1\n",
              "aa^r,o@         1\n",
              "na^m^t          1\n",
              "qy^d^c          1\n",
              "ar^m            1\n",
              "aap^r           1\n",
              "qr^d*           1\n",
              "sv;sd           1\n",
              "sv^e^r          1\n",
              "aa,ar           1\n",
              "%@*             1\n",
              "sd;no           1\n",
              "qy^h@           1\n",
              "qw(^q)          1\n",
              "%,o@            1\n",
              "fa^t            1\n",
              "ft^m            1\n",
              "sv,qy^g@        1\n",
              "fo^c            1\n",
              "bf^2            1\n",
              "qy^d(^q)        1\n",
              "sd^r@           1\n",
              "bk^t            1\n",
              "Name: act_tag, Length: 303, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6G4zBbtB5Ipz"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline BiLSTM Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9biiyP8UiGDe"
      },
      "cell_type": "markdown",
      "source": [
        "To get unique tags. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xxn2s_4jiKkU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_tags = set()\n",
        "for tag in reduced_df['act_tag']:\n",
        "    unique_tags.add(tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RI0iAToHpmkm",
        "colab_type": "code",
        "outputId": "178d9c41-6ee0-4260-b60e-7a75c3d495bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(unique_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LMOX5KwgiPmu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot_encoding_dic = pd.get_dummies(list(unique_tags))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZPHPCxE3iPby",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tags_encoding = []\n",
        "for i in range(0, len(reduced_df)):\n",
        "    tags_encoding.append(one_hot_encoding_dic[reduced_df['act_tag'].iloc[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LVI8QyVzjqWh"
      },
      "cell_type": "markdown",
      "source": [
        "The tags are one hot encoded."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SQJTiffPjUtu"
      },
      "cell_type": "markdown",
      "source": [
        "To create sentence embeddings:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PmkyD1TfjWGO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for i in range(0, len(reduced_df)):\n",
        "    sentences.append(reduced_df['text'].iloc[i].split(\" \"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MlD6L6e3jV-7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wordvectors = {}\n",
        "index = 1\n",
        "for s in sentences:\n",
        "    for w in s:\n",
        "        if w not in wordvectors:\n",
        "            wordvectors[w] = index\n",
        "            index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e7_cjDHrjV1c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = len(max(sentences, key=len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4qgX3kBEZPw",
        "colab_type": "code",
        "outputId": "feef42b5-1511-452a-ef23-23d9ad1071ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "fbuizYlpl51z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LX6DidEvjVWs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_embeddings = []\n",
        "for s in sentences:\n",
        "    sentence_emb = []\n",
        "    for w in s:\n",
        "        sentence_emb.append(wordvectors[w])\n",
        "    sentence_embeddings.append(sentence_emb)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Nr4iEyNTjmlu"
      },
      "cell_type": "markdown",
      "source": [
        "Then we split the dataset into test and train."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GiNZ-iI_jnOF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, np.array(tags_encoding))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_4OaptcmL5cE",
        "colab_type": "code",
        "outputId": "2c7fa806-3ee3-4f08-aefc-6cbbb564e7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_RqMeWe_jron"
      },
      "cell_type": "markdown",
      "source": [
        "And pad the sentences with zero to make all sentences of equal length.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ai9cwv82jufe",
        "outputId": "e81451d0-a6c2-4dca-9523-6fc3a1df0273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYnqg2H2EZQl",
        "colab_type": "code",
        "outputId": "a9f676c7-d72e-4cb2-e162-eadfd51f6b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "test_sentences_X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  13,  250,  105, ...,    0,    0,    0],\n",
              "       [ 102,  111,  177, ...,    0,    0,    0],\n",
              "       [  71,    5,    0, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2,  205,    4, ...,    0,    0,    0],\n",
              "       [ 118, 1315,  521, ...,    0,    0,    0],\n",
              "       [ 284, 1332,  364, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FItlHC1Fjz6y"
      },
      "cell_type": "markdown",
      "source": [
        " The model architecture is as follows: \n",
        " \n",
        " Embedding Layer (to generate word embeddings) \n",
        " Next layer Bidirectional LSTM. \n",
        " Feed forward layer with number of neurons = number of tags. \n",
        " Softmax activation to get probabilities."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LCaX-ptaj8G2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Input, Bidirectional, TimeDistributed, Activation, Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tqv48x3Ovxtw",
        "colab_type": "code",
        "outputId": "84fd51fd-b770-4933-87ae-e8d143dba35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE=len(result);\n",
        "EMBED_SIZE=300;\n",
        "NUMBER_OF_TAGS=len(unique_tags);\n",
        "\n",
        "input1 = Input(shape=(137,), name='input_1')\n",
        "Embeddinglayer1 = Embedding(VOCAB_SIZE,300, name='Embedding_Layer',input_length=MAX_LENGTH)(input1)\n",
        "layer2 = Bidirectional(LSTM(15, name='LSTM_Layer'))(Embeddinglayer1)\n",
        "output = Dense(303, activation = \"softmax\", name='Output_Layer')(layer2)\n",
        "model = Model(inputs=input1, outputs=output)\n",
        "model.compile(optimizer = \"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 137)               0         \n",
            "_________________________________________________________________\n",
            "Embedding_Layer (Embedding)  (None, 137, 300)          67081800  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30)                37920     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 303)               9393      \n",
            "=================================================================\n",
            "Total params: 67,129,113\n",
            "Trainable params: 67,129,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2LkONUKQkSrL",
        "outputId": "46e6022a-a7a1-4bdb-929d-b217fe1e2851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_sentences_X,\n",
        "                    y_train,\n",
        "                    epochs=3,\n",
        "                    batch_size=500,\n",
        "                    verbose=1)\n",
        "\n",
        "score = model.evaluate(test_sentences_X, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3\n",
            "167704/167704 [==============================] - 227s 1ms/step - loss: 2.8472 - acc: 0.3427\n",
            "Epoch 2/3\n",
            "167704/167704 [==============================] - 220s 1ms/step - loss: 2.0379 - acc: 0.4841\n",
            "Epoch 3/3\n",
            "167704/167704 [==============================] - 221s 1ms/step - loss: 1.5743 - acc: 0.6026\n",
            "55902/55902 [==============================] - 361s 6ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ab0ZL1dqkTY4",
        "outputId": "71741427-2065-480f-ffdd-e6198e3a028a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", score[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 63.71328396249732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZiGEPPp1ZxyA",
        "colab_type": "code",
        "outputId": "405d7b73-84c2-4f6e-90cf-069e40152f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "#val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "#val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo-', label='Training acc')\n",
        "#plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XHwoVCEwjEz7"
      },
      "cell_type": "markdown",
      "source": [
        "In addition to overall accuracy, you need to look at the accuracy of some minority classes. Signal-non-understanding ('br') is a good indicator of \"other-repair\" or cases in which the other conversational participant attempts to repair the speaker's error. Summarize/reformulate ('bf') has been used in dialogue summarization. Report the accuracy for these classes and some frequent errors you notice the system makes in predicting them. What do you think the reasons are？"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hKHbOs4WkFaP"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "As the dataset is highly imbalanced, we can simply weight up the minority classes proportionally to their underrepresentation while training. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6L4kNdf6kGEa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_integers = np.argmax(tags_encoding, axis=1)\n",
        "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
        "d_class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xB2McUREkL4B",
        "outputId": "26acaab0-dea2-4797-b1d4-ec97e970cce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_sentences_X, y_train, batch_size=500, epochs=3, class_weight = d_class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "167704/167704 [==============================] - 220s 1ms/step - loss: 6.3019 - acc: 0.4911\n",
            "Epoch 2/3\n",
            "167704/167704 [==============================] - 219s 1ms/step - loss: 5.5482 - acc: 0.5238\n",
            "Epoch 3/3\n",
            "167704/167704 [==============================] - 220s 1ms/step - loss: 5.0042 - acc: 0.5175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ec1eb1ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "KrEGJRHjLgxj",
        "colab_type": "code",
        "outputId": "1e75813e-57a6-4d5a-bd07-6db50d4d8f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_sentences_X, y_test, batch_size=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55902/55902 [==============================] - 25s 443us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RD-YVcKcVdJL",
        "colab_type": "code",
        "outputId": "438909da-4c14-4a8e-c0c8-f90271ded705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(score[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46.84984420865112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fM7VWweco0Et"
      },
      "cell_type": "markdown",
      "source": [
        "Report the overall accuracy and the accuracy of  'br' and 'bf'  classes. Suggest other ways to handle imbalanced classes."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fW4g5mQkkaFv"
      },
      "cell_type": "markdown",
      "source": [
        "Can we improve things by using context information?  Next we try to build a model which predicts DA tag from the sequence of \n",
        "previous DA tags, plus the utterance representation. "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WfrGWuZ6nk4y"
      },
      "cell_type": "markdown",
      "source": [
        "##Using Context for Dialog Act Classification\n",
        "We expect there is valuable sequential information among the DA tags. So in this section we apply a BiLSTM on top of the sentence CNN representation. The CNN model learns textual information in each sentence for DA classification. Here, we use bidirectional-LSTM (BLSTM) to learn the context before and after the current sentence. The left-to-right LSTM output and the one from the reverse direction are concatenated and input to a hidden layer for classification."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Sz693CIUvcca"
      },
      "cell_type": "markdown",
      "source": [
        "Functions for creating weights and biases."
      ]
    },
    {
      "metadata": {
        "id": "BkGHzZVxAxAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9hMj-KaKvfHb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(shape):\n",
        "    return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.05))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oitwAO5ivkbk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bias_init(shape):\n",
        "    return tf.Variable(tf.zeros(shape=shape))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DuJLqgjWqcIf"
      },
      "cell_type": "markdown",
      "source": [
        " This is classical CNN layer used to convolve over embedings tensor and gether useful information from it. The data is represented by hierarchy of features, which can be modelled using a CNN.\n",
        "    \n",
        "      Input(s): \n",
        "              input - word_embedings\n",
        "              filter_size - size of width and height of the Conv kernel\n",
        "              number_of_channels - in this case it is always 1\n",
        "              number_of_filters - how many representation of the input utterance are we going to output from this layer \n",
        "              strides - how many does kernel move to the side and up/down\n",
        "              activation - a activation function\n",
        "              max_pool - boolean value which will trigger a max_pool operation on the output tensor\n",
        "      Output(s): \n",
        "               text_conv layer\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "iKpdU0n3AtiG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UuaiZkOjZGx1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_conv(input, filter_size, number_of_channels, number_of_filters, strides=(1, 1), activation=tf.nn.relu, max_pool=True):\n",
        "    \n",
        "    weights = weights_init([filter_size,filter_size, number_of_channels, number_of_filters])\n",
        "    bias = bias_init([number_of_filters])\n",
        "    \n",
        "    layer = tf.nn.conv2d(input, filter=weights, strides=[1, strides[0], strides[1], 1], padding='SAME')\n",
        "    \n",
        "    if activation != None:\n",
        "        layer = activation(layer)\n",
        "    \n",
        "    if max_pool:\n",
        "        layer = tf.nn.max_pool(layer, ksize=[1, 2, 2 ,1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    \n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mU0Xa3QOqwS3"
      },
      "cell_type": "markdown",
      "source": [
        "    This method is used to create LSTM layer. And the data we’re working with has temporal properties which we want to model as well — hence the use of a LSTM. You can create a BiLSTM by modifying this.\n",
        "    \n",
        "    Input(s): lstm_cell_unitis - used to define the number of units in a LSTM layer\n",
        "              number_of_layers - used to define how many of LSTM layers do we want in the network\n",
        "              batch_size - in this method this information is used to build starting state for the network\n",
        "              dropout_rate - used to define how many cells in a layer do we want to 'turn off'\n",
        "              \n",
        "    Output(s): cell - lstm layer\n",
        "               init_state - zero vectors used as a starting state for the network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QaxUrmPIZI7S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  lstm_layer(lstm_size, number_of_layers, batch_size, dropout_rate):\n",
        "\n",
        "    def cell(size, dropout_rate=None):\n",
        "        layer = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
        "        \n",
        "        return tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout_rate)\n",
        "            \n",
        "    cell = tf.contrib.rnn.MultiRNNCell([cell(lstm_size, dropout_rate) for _ in range(number_of_layers)])\n",
        "    \n",
        "    init_state = cell.zero_state(batch_size, tf.float32)\n",
        "    return cell, init_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UxlRv9dDrcy5"
      },
      "cell_type": "markdown",
      "source": [
        "    Use to transform/reshape conv output to 2d matrix, if it's necessary\n",
        "    \n",
        "    Input(s): Layer - text_cnn layer\n",
        "              batch_size - how many samples do we feed at once\n",
        "              seq_len - number of time steps\n",
        "              \n",
        "    Output(s): reshaped_layer - the layer with new shape\n",
        "               number_of_elements - this param is used as a in_size for next layer"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYxHsBvwZRA4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def flatten(layer, batch_size, seq_len):\n",
        "\n",
        "    dims = layer.get_shape()\n",
        "    number_of_elements = dims[2:].num_elements()\n",
        "    \n",
        "    reshaped_layer = tf.reshape(layer, [batch_size, int(seq_len/2), number_of_elements])\n",
        "    return reshaped_layer, number_of_elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PMOjnT8Drmpa"
      },
      "cell_type": "markdown",
      "source": [
        "    Output layer for the lstm netowrk\n",
        "    \n",
        "    Input(s): lstm_outputs - outputs from the RNN part of the network\n",
        "              input_size - in this case it is RNN size (number of neuros in RNN layer)\n",
        "              output_size - number of neuros for the output layer == number of classes\n",
        "              \n",
        "    Output(s) - logits, "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d84nFOulZkhP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense_layer(input, in_size, out_size, dropout=False, activation=tf.nn.relu):\n",
        "  \n",
        "    weights = weights_init([in_size, out_size])\n",
        "    bias = bias_init([out_size])\n",
        "    layer = tf.matmul(input, weights) + bias\n",
        "    \n",
        "    if activation != None:\n",
        "        layer = activation(layer)\n",
        "    \n",
        "    if dropout:\n",
        "        layer = tf.nn.dropout(layer, 0.5)\n",
        "        \n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VX3KofjJruhZ"
      },
      "cell_type": "markdown",
      "source": [
        "    Function used to calculate loss and minimize it\n",
        "    \n",
        "    Input(s): rnn_out - logits from the fully_connected layer\n",
        "              targets - targets used to train network\n",
        "              learning_rate/step_size\n",
        "    \n",
        "    \n",
        "    Output(s): optimizer - optimizer of choice\n",
        "               loss - calculated loss function"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kNu0_J2VZlKB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_optimizer(logits, targets, learning_rate, ):\n",
        "\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets))\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "    return loss, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mHvKi5bUgfrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Input, Bidirectional, TimeDistributed, Activation, Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s3Acv6U_r1rG"
      },
      "cell_type": "markdown",
      "source": [
        "To create the model you can use these inputs:     \n",
        "       \n",
        "       Input(s): learning_rate/step_size - how fast are we going to find global minima\n",
        "                  batch_size -  the nuber of samples to feed at once\n",
        "                  seq_len - the number of timesteps in unrolled RNN\n",
        "                  vocab_size - the number of nunique words in the vocab\n",
        "                  embed_size - length of word embed vectors\n",
        "                  conv_filters - number of filters in output tensor from CNN layer\n",
        "                  conv_filter_size - height and width of conv kernel\n",
        "                  number_of_lstm_layers - the number of layers used in the LSTM part of the network\n",
        "                  lstm_units - the number of neurons/cells in a LSTM layer"
      ]
    },
    {
      "metadata": {
        "id": "r2hSI6l8wOs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DATagging(object):\n",
        "    \n",
        "    def __init__(self, learning_rate=0.001, batch_size=100, seq_len=138, vocab_size=10000, embed_size=300,\n",
        "                conv_filters=32, conv_filter_size=5, number_of_lstm_layers=1, lstm_units=128):\n",
        "        \n",
        "        tf.reset_default_graph()\n",
        "        \n",
        "        ##### INPUTS #############\n",
        "        \n",
        "        self.inputs = tf.placeholder(tf.int32, [batch_size, seq_len], name='inputs_reviews')\n",
        "        self.targets = tf.placeholder(tf.float32, [batch_size, 303], name='target_sentiment')\n",
        "        self.keep_probs = tf.placeholder(tf.float32, name='keep_probs')\n",
        "        print(\" INPUTS: \",self.inputs)\n",
        "        \n",
        "        ##### EMBEDDING LAYER #####\n",
        "        \n",
        "        word_embedings = tf.Variable(tf.random_uniform([vocab_size, embed_size]))\n",
        "        \n",
        "        EMBEDDING_LAYER = tf.nn.embedding_lookup(word_embedings, self.inputs)\n",
        "        print(\"EMBEDDING_LAYER: \",EMBEDDING_LAYER)\n",
        "        \n",
        "        embedding_exp = tf.expand_dims(EMBEDDING_LAYER, -1)\n",
        "        print(\"embedding_exp: \",embedding_exp)\n",
        "        \n",
        "        ##### CONVOLUTION LAYER #####\n",
        "        \n",
        "        conv_layer= text_conv(embedding_exp, conv_filter_size, 1 , conv_filters, strides=(1, 1), activation=tf.nn.relu, max_pool=True)\n",
        "        print(\"CONVOLUTION_LAYER: \",conv_layer)\n",
        "        \n",
        "        flatten_conv, number_of_elements =flatten(conv_layer, batch_size, seq_len)\n",
        "        print(\"FLATTEN_CONV: \",flatten_conv)\n",
        "        \n",
        "        ##### LSTM LAYER ############\n",
        "        \n",
        "        cell,init_state =lstm_layer(lstm_units, number_of_lstm_layers, batch_size,self.keep_probs)\n",
        "        outputs, states = tf.nn.dynamic_rnn(cell, flatten_conv, initial_state=init_state)\n",
        "        print(\"LSTM_OUTPUT: \", outputs)\n",
        "        \n",
        "        squeezed_outputs=tf.squeeze(tf.slice(outputs,[0,0,0],[-1,1,-1]))\n",
        "        print(\"SQUEEZED_LSTM_OUTPUT: \",squeezed_outputs)\n",
        "        \n",
        "        ##### OUTPUT LAYER ############\n",
        "        \n",
        "        logits=dense_layer(squeezed_outputs, lstm_units, 303, dropout=False, activation=tf.nn.relu)\n",
        "        print(\"OUTPUT_LAYER: \",logits)\n",
        "        \n",
        "        self.loss, self.opt =loss_optimizer(logits, self.targets, learning_rate)\n",
        "        \n",
        "        #### PREDICTION OF THE CLASSES ###########\n",
        "        \n",
        "        preds = tf.nn.softmax(logits)\n",
        "        currect_pred=tf.equal(tf.argmax(preds, 1), tf.argmax(self.targets, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(currect_pred, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Vdd4uJzoE8s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, np.array(tags_encoding),train_size=160000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "D3bVXv36axfu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = DATagging(learning_rate=0.001, \n",
        "                     batch_size=200, \n",
        "                     seq_len=138, \n",
        "                     vocab_size=len(wordvectors) + 1, \n",
        "                     embed_size=300,\n",
        "                     conv_filters=32, \n",
        "                     conv_filter_size=5, \n",
        "                     number_of_lstm_layers=1, \n",
        "                     lstm_units=128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kI7_Uqseib5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LENGTH=138 \n",
        "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OUua3NQvdD9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "epochs = 5\n",
        "batch_size = 200\n",
        "drop_rate = 0.7 # 1- 0.7= 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1c30FQPdxnS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMz6YkemddRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "    epoch_loss = []\n",
        "    train_accuracy = []\n",
        "    for ii in tqdm(range(0, len(train_sentences_X), batch_size)):\n",
        "        X_batch = train_sentences_X[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size].reshape(-1, NUMBER_OF_TAGS)\n",
        "        \n",
        "        c, _, a = session.run([model.loss, model.opt, model.accuracy], feed_dict={model.inputs:X_batch, \n",
        "                                                                                  model.targets:y_batch,\n",
        "                                                                                  model.keep_probs:drop_rate})\n",
        "        \n",
        "        epoch_loss.append(c)\n",
        "        train_accuracy.append(a)\n",
        "        \n",
        "    \n",
        "    print(\"Epoch: {}/{}\".format(i, epochs), \" | Epoch loss: {}\".format(np.mean(epoch_loss)), \n",
        "          \" | Mean train accuracy: {}\".format(np.mean(train_accuracy)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mqL4prVYdR7u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "\n",
        "ii = 0\n",
        "while ii + batch_size <= len(X_test):\n",
        "    X_batch = test_sentences_X[ii:ii+batch_size]\n",
        "    y_batch = y_test[ii:ii+batch_size].reshape(-1, NUMBER_OF_TAGS)\n",
        "\n",
        "    a = session.run([model.accuracy], feed_dict={model.inputs:X_batch, \n",
        "                                                 model.targets:y_batch, \n",
        "                                                 model.keep_probs:1.0})\n",
        "    \n",
        "    accuracy.append(a)\n",
        "    ii += batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZYoD0Y4m0f1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy: {}\".format(np.mean(accuracy)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSObk6i6yDQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RKMmrfuisKGJ"
      },
      "cell_type": "markdown",
      "source": [
        "Compared to the baseline using BiLSTM for utterance classification, the second method effectively leverage context information and achieve better performance. Report your overall accuracy. Did context help disambiguate and better predict the minority classes ('br' and 'bf')? What are frequent errors? Show one positive example where adding context changed the prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gUZt48JgrE34"
      },
      "cell_type": "markdown",
      "source": [
        "## Advanced: Creating End-To-End Dialogue System"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zE63Q5guuPdA"
      },
      "cell_type": "markdown",
      "source": [
        "In the last section we want to create end-to-end dialogue system, following on from the seq2seq MT labs you've \n",
        "just done. This is an advanced part of the assignment and worth 10 marks (20%) in total. In end-to-end dialogue systems, the encoder represents each utterance with a vector. The utterance vector is the hidden state after the last token of the utterance has been processed. The context LSTM keeps track of past utterances. The hidden state can be explained as the state of the dialogue system. The next utterance prediction is performed by a decoder LSTM, which takes the hidden state of the last LSTM and produces a probability distribution over the tokens in the next utterance. You can take the DA LSTM state of last section as input to a decoder which tries to generate the next utterance. You can add attention and monitor the performance. Instead of evaluating by an automatic evaluation method, you can show us some of the interesting predictions. \n"
      ]
    }
  ]
}